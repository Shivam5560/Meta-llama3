{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Llama3 8B instruct model fine-tuned on Bhojpuri news headline generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!conda install pytorch-cuda=<12.1/11.8> pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers\n",
    "!pip install --no-deps trl peft accelerate bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    max_seq_length=8000,\n",
    "    dtype=None,\n",
    "    token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install numba\n",
    "# from numba import cuda\n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = 'The following passage is content from a news report. Please summarize this passage in one sentence or less.'\n",
    "    inputs       = examples[\"content\"]\n",
    "    outputs      = examples[\"headline\"]\n",
    "    texts = []\n",
    "    for j,k  in zip(inputs,outputs):\n",
    "        text = alpaca_prompt.format(instructions,j,k) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {'text':texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"shivam9980/bhojpuri-news\", split = \"train\",token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login '8a8c6f69425f9bc32d2ab64a9c2976149ee1c460'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator(device_ids=[0, 1]) \n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = accelerator.prepare_model(model),\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 4096,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 25,\n",
    "        num_train_epochs=2,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"wandb\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub_merged(\"shivam9980/llama-8b-news-bhojpuri\", tokenizer, save_method = \"lora\", token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = \"\"\"यूपी के बदायूं जिले में मंगलवार की शाम को दो बच्चों की हत्या की सनसनीखेज वारदात के दूसरे आरोपी को पुलिस ने बरेली से गिरफ्तार किया है। बदायूं पुलिस ने बरेली की बरादरी थाना पुलिस से सहयोग से सेटेलाइट चौराहे से पकड़ा है। पुलिस उसे बदायूं ले गई है। जावेद पर 25 हजार रुपये का इनाम था। बदायूं के एसएसपी आलोक प्रियदर्शी ने बताया आरोपी जावेद को बरेली से गिरफ्तार कर लिया गया है। जावेद  वहां की बारादरी पुलिस चौकी में खुद को सरेंडर करने पहुंचा था इसके बाद वीडियो भी जारी किया।वीडियो में एक युवक ऑटो में बैठा दिखाई दे रहा है। वह अपना नाम जावेद बता रहा है। वह कहता है कि उसने कुछ नहीं किया है। जो कुछ भी किया है, उसके बड़े भाई ने किया है। पुलिस जावेद से पूछताछ कर रही है।फरार आरोपी जावेद पर 25000 का इनाम घोषित आरोपी जावेद की लगातार पुलिस तलाश कर रही थी। उसकी तलाश में पुलिस की कई टीमें लगीं थीं। जावेद पर 25000 रुपये का इनाम घोषित कर दिया गया था। आरोपी  से पूछताछ के बाद ही हत्याकांड की वजह का खुलासा हो सकेगा।  आपको बता दें कि उत्तर प्रदेश के बदायूं जिले में मंगलवार की शाम को मंडी समिति पुलिस चौकी से 500 मीटर दूर स्थित बाबा कॉलोनी में एक ठेकेदार विनोद ठाकुर के दो बेटों आयुष (13) और अहान (6) की चाकू से गला रेतकर हत्या कर दी गई थी। ठेकेदार के मकान के सामने हेयर सैलून चलाने वाले साजिद ने इस सनसनीखेज वारदात को अंजाम दिया था। वारदात के तीन घंटे के बाद पुलिस ने मौके से करीब दो किमी दूर घेराबंदी कर आरोपी साजिद को मुठभेड़ में ढेर कर दिया था। मुठभेड़ में इंस्पेक्टर गौरव विश्नोई भी घायल हुए थे। उन्हें अस्पताल में भर्ती कराया गया। वहीं, आरोपियों के दूसरे समुदाय के होने से गुस्सा भड़क उठा। जाम लगाकर हंगामा करते हुए दूसरे समुदाय के तीन खोखों में आग लगा दी। इसके बाद पुलिस ने आरोपी साजिद को मौके से करीब दो किमी. दूर पुरानी चांदमारी के पास घेराबंदी कर मुठभेड़ में ढेर कर दिया। उसके दो साथियों की तलाश की जा रही है।पुलिस हत्या की वजह पता कर रही है। जानकारी के अनुसार, बाबा कॉलोनी में मजिया रोड के रहने वाले ठेकेदार ‘हर घर जल योजना’ के तहत ओवरहेड टैंक का निर्माण कराते हैं। उनके मकान के सामने ही कस्बा सखानू के रहने वाले साजिद की बाल काटने की दुकान है। विनोद की पत्नी संगीता अपने मकान के निचले हिस्से में ब्यूटी पार्लर चलाती हैं। इसके चलते परिवारों के काफी अच्छे संबंध थे। साजिद का उनके घर आना जाना भी था। मंगलवार रात संगीता तीन बच्चों आयुष, अहान और पीयूष (8) के साथ घर पर थीं, जबकि विनोद लखीमपुर खीरी गए हुए थे। साजिद शाम चार बजे दुकान बंद करके चला गया था।मुलाकात के लिए आया और ऊपर ले जाकर मार डालासाजिद रात आठ बजे अपने दो साथियों के साथ आया तो संगीता उनके लिए चाय बनाने अंदर को चली गईं। तभी साजिद उनके दो बेटों आयुष और अहान को अपने साथ ऊपर ले गया। साथ ही, पीयूष से पानी लाने के लिए कहा। जब तक वह पानी लेकर ऊपर पहुंचा तब तक साजिद ने धारदार हथियार से आयुष और अहान की हत्या कर दी। सामने आए पीयूष पर भी चाकू से वार किया तो वह चीखता हुआ नीचे भागा। पीयूष के पीछे साजिद भी दौड़ा तो यह देख मां ने शोर मचाया। शोर सुनकर आसपास के लोग दौड़े और मां-बेटे को बाहर खींचकर दरवाजा बंद कर दिया। आरोपी की दुकान के साथ, चार दुकानें फूंकीसूचना पर पहुंची पुलिस साजिद की तलाश में जुट गई। इस बीच आसपास के लोग बड़ी संख्या में इकट्ठा हो गए। नृशंस हत्या देख उनका गुस्सा बढ़ने लगा। इधर आक्रोशित भीड़ ने साजिद की दुकान तोड़कर सामान निकाला और सड़क पर रखकर फूंक दिया। आसपास के चार दुकानों को आग के हवाले कर दिया। बुधवार को मृतक बच्चों के पिता की शिकायत पर पुलिस ने आरोपी साजिद और उसके भाई जावेद के खिलाफ एफआईआर दर्ज की है। एफआईआर में लिखा है कि \"आरोपी साजिद ने मेरी पत्नी से कहा कि उसे पैसे चाहिए क्योंकि उसकी पत्नी बच्चे को जन्म देने वाली है। जब वह पैसे लेने के लिए अंदर गई, तो उसने कहा कि वह अस्वस्थ महसूस कर रहा है और छत पर टहलने जाना चाहता है और मेरे बेटों (मृतक) को अपने साथ ले गया। उसने अपने भाई जावेद को भी छत पर बुला लिया। जब मेरी पत्नी लौटी तो उसने साजिद और जावेद को हाथों में चाकू लिए देखा। साजिद ने मेरे जीवित बेटे पर भी हमला करने की कोशिश की और उसे चोटें आईं। दोनों भाग रहे थे और साजिद ने मेरी पत्नी से कहा कि आज उसने अपना काम पूरा कर लिया है।\"\"\"\n",
    "# # alpaca_prompt = Copied from above\n",
    "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "# inputs = tokenizer(\n",
    "# [\n",
    "#     alpaca_prompt.format(\n",
    "#         \"The following passage is content from a news report. Please summarize this passage in one sentence or less.\", # instruction\n",
    "#         content, # input\n",
    "#         \"\", # output - leave this blank for generation!\n",
    "#     )\n",
    "# ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "# tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
